{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.genfromtxt('data.csv',dtype = None, encoding = 'UTF-8', names = True, delimiter = ',')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing \n",
    "from sklearn import preprocessing\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "encoder.fit(data['diagnosis'])\n",
    "# encoder.transform(data['diagnosis'])\n",
    "diagnosis = encoder.transform(data['diagnosis']).astype(int)\n",
    "new_data = diagnosis.reshape(-1,1)\n",
    "for i in range(2,len(data.dtype.names)):\n",
    "    new_data = np.concatenate((new_data,np.expand_dims(data[data.dtype.names[i]],axis = 0).T),axis = 1)\n",
    "new_data[:,1:] = preprocessing.normalize(new_data[:,1:],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train, y_test = train_test_split(new_data[:,1:],new_data[:,0],test_size = .2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('admin_training',x_train)\n",
    "np.save('admin_y',y_train)\n",
    "y = np.expand_dims(y_train, axis = 0)\n",
    "admin_data = np.concatenate((x_train, y.T), axis = 1)\n",
    "data_file = open(\"data_training.csv\",\"w\")\n",
    "for row in admin_data:\n",
    "    data_file.write(\",\".join(str(feature) for feature in row)+\"\\n\")\n",
    "data_file.close()\n",
    "\n",
    "np.save(\"admin_data\",admin_data)\n",
    "np.save('client_training',x_test)\n",
    "np.save('client_y',y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Failed to interpret file <_io.BufferedRandom name=62> as a pickle",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-563241caf825>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTemporaryFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0madmin_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                 raise IOError(\n\u001b[0;32m--> 431\u001b[0;31m                     \"Failed to interpret file %s as a pickle\" % repr(file))\n\u001b[0m\u001b[1;32m    432\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mown_fid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Failed to interpret file <_io.BufferedRandom name=62> as a pickle"
     ]
    }
   ],
   "source": [
    "from tempfile import TemporaryFile\n",
    "tf = TemporaryFile()\n",
    "np.save(tf,admin_data)\n",
    "data = np.load(tf)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 fold validation\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, precision_score,recall_score,f1_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "kf = KFold(n_splits = 10)\n",
    "counter = 1\n",
    "\n",
    "for train_index, test_index in kf.split(x_train):\n",
    "    training_samples = x_train[train_index]\n",
    "    training_y = y_train[train_index]\n",
    "    test_samples = x_train[test_index]\n",
    "    test_y = y_train[test_index]\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    lda.fit(training_samples,training_y)\n",
    "    predict_y = lda.predict(test_samples)\n",
    "#     print(\"test_y: {}\".format(test_y))\n",
    "#     print(\"predict_y: {}\".format(predict_y))\n",
    "    file = open('model_evaluation_{}.txt'.format(counter),'w+')\n",
    "    file.write(\"iteration: {}\\n\".format(counter))\n",
    "    file.write(\"confusion matrix: {}\\n\".format(confusion_matrix(test_y,predict_y)))\n",
    "    file.write(\"precision: {}\\n\".format(precision_score(test_y,predict_y)))\n",
    "    file.write(\"recall: {}\\n\".format(recall_score(test_y,predict_y)))\n",
    "    file.write(\"f1-score: {}\\n\".format(f1_score(test_y,predict_y)))\n",
    "    file.close()\n",
    "    # to store the model\n",
    "    joblib.dump(lda, 'model_{}'.format(counter))\n",
    "    counter += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
